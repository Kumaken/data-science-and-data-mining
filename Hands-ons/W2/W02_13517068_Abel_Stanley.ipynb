{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Week 02 Handson - Data Preprocessing #01\n",
    "In this hands-on session, we will learn some basic data pre-processings, which include:\n",
    "1. duplicated data handling,\n",
    "2. missing value handling,\n",
    "3. data transformation (scalling and converting 'categorical data' to 'numerical data'),\n",
    "4. outliers removal (for data preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset \"raw-flight-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Carrier</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>11433</td>\n",
       "      <td>13303</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>14869</td>\n",
       "      <td>12478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>14057</td>\n",
       "      <td>14869</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>15016</td>\n",
       "      <td>11433</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>11193</td>\n",
       "      <td>12892</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayofMonth  DayOfWeek Carrier  OriginAirportID  DestAirportID  DepDelay  \\\n",
       "0          19          5      DL            11433          13303      -3.0   \n",
       "1          19          5      DL            14869          12478       0.0   \n",
       "2          19          5      DL            14057          14869      -4.0   \n",
       "3          19          5      DL            15016          11433      28.0   \n",
       "4          19          5      DL            11193          12892      -6.0   \n",
       "\n",
       "   ArrDelay  \n",
       "0       1.0  \n",
       "1      -8.0  \n",
       "2     -15.0  \n",
       "3      24.0  \n",
       "4     -11.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# start: py -m notebook\n",
    "\n",
    "# read csv file into 'df' dataframe\n",
    "df = pd.read_csv('./raw-flight-data.csv', sep = \",\")\n",
    "\n",
    "# print some data rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 01 (M01)\n",
    "The given dataset is still a 'raw dataset' with duplicated data and missing values,<br>\n",
    "1. In M01, please delete the duplicated data (keep only one) and return a dataframe with no duplicated data. **Hint:** use pandas API to handle the duplicated data,<br>\n",
    "2. Print how many duplicated data (that are removed). **Hint:** calculate the difference of row numbers, before and after duplicate removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows Removal\n",
      "Before:  2719418\n",
      "After:  2696983\n",
      "Diff:  22435\n"
     ]
    }
   ],
   "source": [
    "# write you own code for M01 here\n",
    "old_row_num = len(df)\n",
    "m1_df = df.drop_duplicates(keep=\"first\", inplace=False)\n",
    "new_row_num = len(m1_df)\n",
    "\n",
    "print('Duplicate Rows Removal')\n",
    "print(\"Before: \", old_row_num)\n",
    "print(\"After: \", new_row_num)\n",
    "print(\"Diff: \", old_row_num-new_row_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M02\n",
    "In M02, we will handle data rows having missing values. **Note:** in the given dataset, the missing values are only in the columns of ```DepDelay``` and ```ArrDelay```.\n",
    "1. First and naive approach is by deleting the data rows having missing value. From data in M01, use pandas API to remove data rows with 'missing value', with specifications: (i) column subset to be checked = ```DepDelay``` and ```ArrDelay```, (ii) delete the data rows with **at least one missing value** in the given subset in (i),\n",
    "2. Print the number missing rows from (1),\n",
    "3. Another approach to handle missing values is by filling those missing values by their corresponding mean values, most frequent values, interpolated values, etc. In this M02, fill the missing values in the columns of ```DepDelay``` and ```ArrDelay``` by their corresponding mean values.\n",
    "4. Perform 'drop missing value', similar to (1), to the result of (3). Calculate the difference of row numbers before and after. You should get '0' for this. \n",
    "5. In your opinion, what are the differences between those two techniques (delete missing values vs filling with mean values)? Which one do you prefer? Please explain your argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing row numbers: 23798\n"
     ]
    }
   ],
   "source": [
    "# write you own code for M02 here\n",
    "m2_df_1 = m1_df.dropna(axis=0, # delete row \n",
    "            how='any', # if one of them is missing, drop\n",
    "            subset=['DepDelay', 'ArrDelay'], #columns to be deleted\n",
    "            inplace= False)\n",
    "print('Missing row numbers:', len(m1_df) - len(m2_df_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Difference:  0\n"
     ]
    }
   ],
   "source": [
    "# m2_df_3[['DepDelay', 'ArrDelay']] = m1_df[['DepDelay', 'ArrDelay']].fillna(value=df.mean())\n",
    "m2_df_3 = m1_df.fillna(value=df.mean(numeric_only=True))\n",
    "m2_df_4 = m2_df_3.dropna(axis=0, # delete row \n",
    "            how='any', # if one of them is missing, drop\n",
    "            subset=['DepDelay', 'ArrDelay'], #columns to be deleted\n",
    "            inplace= False)\n",
    "print(\"4. Difference: \", len(m2_df_3) - len(m2_df_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deciding whether to remove or replace/impute the missing data we have to understand the reason why data goes missing:\n",
    "If MAR(missing at random) or MCAR(missing completely at random) then dropping is generally considered safe depending upon their occurrences. On the other hand if MNAR(missing not at random) then removing observations with missing values can produce a bias in the model.\n",
    "\n",
    "Other than that:\n",
    "\n",
    "Replacing/imputation is more appropriate if the percentage of missing data is low. If the portion of missing data is too high, the results lack natural variation that could result in an effective model.\n",
    "Removing data is more appropriate when dealing with data that is missing at random, related data can be deleted to reduce bias. Removing data may not be the best option if there are not enough observations to result in a reliable analysis.\n",
    "\n",
    "For this case:\n",
    "\n",
    "Because the missing value percentage is only 0.88% (23798 rows), it's safe to replace/impute them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M03\n",
    "There is a 'Carrier' column in the given dataset, which is a \"categorical variable\". \n",
    "1. To build a learning model, what we need is numerical data so that our data can be processed by the learning model. Please convert the \"categorical valriable\" in the column of \"Carrier\" to \"numerical variable\". E.g., given categorical variable values of [A, B, A, C], we expect to get [0, 1, 0, 2] or [1, 2, 1, 3]. Thus, a row with the column value of \"A\", its value should be replaced with \"0\" (if you use this --> [0, 1, 0, 2]) or \"1\" (if you use this --> [1, 2, 1, 3])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# write you own code for M03 here\n",
    "numerical_carrier = pd.factorize(m2_df_4['Carrier'])[0] # only take the labels, [1] is the unique columns value\n",
    "print(numerical_carrier)\n",
    "# pd.factorize(['A','B','A','C'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M04\n",
    "In some learning methods, we may perform data transformations so that we can expect a better performance (accuracy). One of the popular data transformation is **scalling**. Please do scalling the data column of \"DepDelay\" to [-1, 1]. <br>\n",
    "**Hint:** In this hands-on session, don't use libary to do scalling, we expect you use scalling formula of:<br><br>\n",
    "$$ \\widehat{X} = \\frac{(X-X_{min}) \\times (BA - BB)}{X_{max}-X_{min}} + BB,$$ <br>\n",
    "Where:<br>\n",
    "$\n",
    "\\begin{align}\n",
    "    \\widehat{X} &= \\text{scalled value}\\\\\n",
    "    X &= \\text{value being scalled}\\\\\n",
    "    X_{max}, X_{min} &= \\text{max of } X \\text{, min of }X\\\\\n",
    "    BA &= \\text{batas atas, untuk kasus kita adalah 1}\\\\\n",
    "    BB &= \\text{batas bawah, untuk kasus kita adalah -1}\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719413</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719414</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719415</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719416</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719417</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2719418 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DepDelay\n",
       "0            -3.0\n",
       "1             0.0\n",
       "2            -4.0\n",
       "3            28.0\n",
       "4            -6.0\n",
       "...           ...\n",
       "2719413       1.0\n",
       "2719414      -2.0\n",
       "2719415      18.0\n",
       "2719416      10.0\n",
       "2719417       0.0\n",
       "\n",
       "[2719418 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write you own code for M04 here\n",
    "def scaling(X, Xmax, Xmin, BA, BB):\n",
    "    return ((X-Xmin) * (BA-BB) / (Xmax-Xmin) + BB)\n",
    "\n",
    "Xmax = m2_df_4['DepDelay'].max()\n",
    "Xmin = m2_df_4['DepDelay'].min()\n",
    "\n",
    "m2_df_4['DepDelay'] = scaling(m2_df_4['DepDelay'], Xmax, Xmin, 1, -1)\n",
    "\n",
    "df[['DepDelay']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M05\n",
    "In raw data, there may be outliers and they should be removed before we use our data to our learning model. There are several approaches and one of them is by using Interquartile Range (IQR). The IQR can be used to identify outliers by defining limits on the sample values that are: (i) a factor $k$ of the IQR **below** the 25th percentile (Q1), **or** (ii) a factor $k$ of the IQR **above** the 75th percentile (Q3). The common value for the factor $k$ is the value 1.5 (thus, the outliers condition is below $(Q1 - 1.5 * IQR)$ or above $(Q3 + 1.5 * IQR)$). A factor $k$ of 3 or more can be used to identify values that are extreme outliers (far outs).\n",
    "\n",
    "In M05, use the column ```ArrDelay``` to filter out the outliers data with $k=1.5$ and one more $k$ value you think it's a good value to filter out the outliers. Please also: (i) print the value of $Q1, Q2, IQR, (Q1 - k * IQR), (Q3 + k * IQR)$ and (ii) count how many outliers you successfully remove by using $k=1.5$ and the other $k$ you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write you own code for M05 here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission \n",
    "Submit this ipynb file to course portal similar to what you have done in the Week 01 Handson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "a65c17a7-e1ca-4afb-b7a7-bcf261eb3d3f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
